{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "x = pd.read_csv('x_trainings_daten_stuttart.csv')\n",
    "y = pd.read_csv('y_trainings_daten_stuttart.csv')    \n",
    "\n",
    "# merge on date\n",
    "df = pd.merge(x, y, on='date')\n",
    "df.to_csv('trainings_daten_stuttart.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>year</th>\n",
       "      <th>week</th>\n",
       "      <th>hour</th>\n",
       "      <th>dayOfMonth</th>\n",
       "      <th>day_x_hour</th>\n",
       "      <th>lagged_revenue_D_1</th>\n",
       "      <th>lagged_revenue_H_1</th>\n",
       "      <th>holiday_mean_encoded</th>\n",
       "      <th>current_weather_component_1</th>\n",
       "      <th>current_weather_component_2</th>\n",
       "      <th>weather_diff_to_exp_component_1</th>\n",
       "      <th>coronaImpact</th>\n",
       "      <th>revenue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-01-01 14:00:00</td>\n",
       "      <td>2016</td>\n",
       "      <td>52</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>714</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.528081</td>\n",
       "      <td>-0.191760</td>\n",
       "      <td>0.443502</td>\n",
       "      <td>1.0</td>\n",
       "      <td>58.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-01-01 15:00:00</td>\n",
       "      <td>2016</td>\n",
       "      <td>52</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>715</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.502798</td>\n",
       "      <td>-0.184728</td>\n",
       "      <td>0.428460</td>\n",
       "      <td>1.0</td>\n",
       "      <td>413.580000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-01-01 16:00:00</td>\n",
       "      <td>2016</td>\n",
       "      <td>52</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>716</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.217124</td>\n",
       "      <td>-0.219914</td>\n",
       "      <td>0.227167</td>\n",
       "      <td>1.0</td>\n",
       "      <td>432.590000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-01-01 17:00:00</td>\n",
       "      <td>2016</td>\n",
       "      <td>52</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>717</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.064720</td>\n",
       "      <td>-0.256727</td>\n",
       "      <td>0.029202</td>\n",
       "      <td>1.0</td>\n",
       "      <td>643.620000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-01-01 18:00:00</td>\n",
       "      <td>2016</td>\n",
       "      <td>52</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>718</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.350093</td>\n",
       "      <td>-0.285155</td>\n",
       "      <td>-0.172097</td>\n",
       "      <td>1.0</td>\n",
       "      <td>636.320000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27705</th>\n",
       "      <td>2023-09-30 19:00:00</td>\n",
       "      <td>2023</td>\n",
       "      <td>39</td>\n",
       "      <td>19</td>\n",
       "      <td>30</td>\n",
       "      <td>619</td>\n",
       "      <td>6796.204746</td>\n",
       "      <td>1418.415938</td>\n",
       "      <td>1006.216532</td>\n",
       "      <td>0.286742</td>\n",
       "      <td>0.259476</td>\n",
       "      <td>0.225284</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1503.232958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27706</th>\n",
       "      <td>2023-09-30 20:00:00</td>\n",
       "      <td>2023</td>\n",
       "      <td>39</td>\n",
       "      <td>20</td>\n",
       "      <td>30</td>\n",
       "      <td>620</td>\n",
       "      <td>6796.204746</td>\n",
       "      <td>888.685398</td>\n",
       "      <td>943.098579</td>\n",
       "      <td>0.370658</td>\n",
       "      <td>0.169524</td>\n",
       "      <td>0.267972</td>\n",
       "      <td>1.0</td>\n",
       "      <td>859.612593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27707</th>\n",
       "      <td>2023-09-30 21:00:00</td>\n",
       "      <td>2023</td>\n",
       "      <td>39</td>\n",
       "      <td>21</td>\n",
       "      <td>30</td>\n",
       "      <td>621</td>\n",
       "      <td>6796.204746</td>\n",
       "      <td>401.546930</td>\n",
       "      <td>757.453552</td>\n",
       "      <td>0.424010</td>\n",
       "      <td>0.079618</td>\n",
       "      <td>0.296878</td>\n",
       "      <td>1.0</td>\n",
       "      <td>367.365510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27708</th>\n",
       "      <td>2023-09-30 22:00:00</td>\n",
       "      <td>2023</td>\n",
       "      <td>39</td>\n",
       "      <td>22</td>\n",
       "      <td>30</td>\n",
       "      <td>622</td>\n",
       "      <td>6796.204746</td>\n",
       "      <td>167.692219</td>\n",
       "      <td>427.740709</td>\n",
       "      <td>0.455768</td>\n",
       "      <td>0.053625</td>\n",
       "      <td>0.331928</td>\n",
       "      <td>1.0</td>\n",
       "      <td>166.480406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27709</th>\n",
       "      <td>2023-09-30 23:00:00</td>\n",
       "      <td>2023</td>\n",
       "      <td>39</td>\n",
       "      <td>23</td>\n",
       "      <td>30</td>\n",
       "      <td>623</td>\n",
       "      <td>6796.204746</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>136.389807</td>\n",
       "      <td>0.401862</td>\n",
       "      <td>0.035235</td>\n",
       "      <td>0.306485</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27710 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      date  year  week  hour  dayOfMonth  day_x_hour  \\\n",
       "0      2017-01-01 14:00:00  2016    52    14           1         714   \n",
       "1      2017-01-01 15:00:00  2016    52    15           1         715   \n",
       "2      2017-01-01 16:00:00  2016    52    16           1         716   \n",
       "3      2017-01-01 17:00:00  2016    52    17           1         717   \n",
       "4      2017-01-01 18:00:00  2016    52    18           1         718   \n",
       "...                    ...   ...   ...   ...         ...         ...   \n",
       "27705  2023-09-30 19:00:00  2023    39    19          30         619   \n",
       "27706  2023-09-30 20:00:00  2023    39    20          30         620   \n",
       "27707  2023-09-30 21:00:00  2023    39    21          30         621   \n",
       "27708  2023-09-30 22:00:00  2023    39    22          30         622   \n",
       "27709  2023-09-30 23:00:00  2023    39    23          30         623   \n",
       "\n",
       "       lagged_revenue_D_1  lagged_revenue_H_1  holiday_mean_encoded  \\\n",
       "0                     NaN                 NaN                   NaN   \n",
       "1                     NaN                 NaN                   NaN   \n",
       "2                     NaN                 NaN                   NaN   \n",
       "3                     NaN                 NaN                   NaN   \n",
       "4                     NaN                 NaN                   NaN   \n",
       "...                   ...                 ...                   ...   \n",
       "27705         6796.204746         1418.415938           1006.216532   \n",
       "27706         6796.204746          888.685398            943.098579   \n",
       "27707         6796.204746          401.546930            757.453552   \n",
       "27708         6796.204746          167.692219            427.740709   \n",
       "27709         6796.204746            0.000000            136.389807   \n",
       "\n",
       "       current_weather_component_1  current_weather_component_2  \\\n",
       "0                         0.528081                    -0.191760   \n",
       "1                         0.502798                    -0.184728   \n",
       "2                         0.217124                    -0.219914   \n",
       "3                        -0.064720                    -0.256727   \n",
       "4                        -0.350093                    -0.285155   \n",
       "...                            ...                          ...   \n",
       "27705                     0.286742                     0.259476   \n",
       "27706                     0.370658                     0.169524   \n",
       "27707                     0.424010                     0.079618   \n",
       "27708                     0.455768                     0.053625   \n",
       "27709                     0.401862                     0.035235   \n",
       "\n",
       "       weather_diff_to_exp_component_1  coronaImpact      revenue  \n",
       "0                             0.443502           1.0    58.800000  \n",
       "1                             0.428460           1.0   413.580000  \n",
       "2                             0.227167           1.0   432.590000  \n",
       "3                             0.029202           1.0   643.620000  \n",
       "4                            -0.172097           1.0   636.320000  \n",
       "...                                ...           ...          ...  \n",
       "27705                         0.225284           1.0  1503.232958  \n",
       "27706                         0.267972           1.0   859.612593  \n",
       "27707                         0.296878           1.0   367.365510  \n",
       "27708                         0.331928           1.0   166.480406  \n",
       "27709                         0.306485           1.0     0.000000  \n",
       "\n",
       "[27710 rows x 14 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('trainings_daten_stuttart_neu.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_data = pd.read_csv(\"trainings_daten_stuttart_neu.csv\")\n",
    "\n",
    "last_date = train_data.iloc[train_data.last_valid_index()].date\n",
    "last_date = pd.to_datetime(last_date)\n",
    "last_date = last_date - pd.DateOffset(months=1)\n",
    "test_data = train_data[pd.to_datetime(train_data.date) > last_date]\n",
    "test_data = test_data.drop(columns=[\"revenue\"])\n",
    "train_data = train_data[pd.to_datetime(train_data.date) <= last_date]\n",
    "train_data = train_data.dropna()\n",
    "\n",
    "test_data.set_index(\"date\", inplace=True)\n",
    "train_data.set_index(\"date\", inplace=True)\n",
    "test_data.to_csv(\"test_data_till_2023.csv\")\n",
    "train_data.to_csv(\"train_data_till_2023.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_20029/3773211973.py:2: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "# lade train_data_till_2023.csv und schränke das auf das letzte Jahr ein (so dass das neue df noch ein jahr an daten hat) und speichere das als train_data_till_2023_last_year.csv\n",
    "import pandas as pd\n",
    "\n",
    "train_data = pd.read_csv(\"train_data_till_2023.csv\")\n",
    "last_date = train_data.iloc[train_data.last_valid_index()].date\n",
    "last_date = pd.to_datetime(last_date)\n",
    "last_date = last_date - pd.DateOffset(years=1)\n",
    "train_data = train_data[pd.to_datetime(train_data.date) > last_date]\n",
    "train_data.set_index(\"date\", inplace=True)\n",
    "train_data.to_csv(\"train_data_till_2023_last_year.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date                                object\n",
       "year                                 int64\n",
       "week                                 int64\n",
       "hour                                 int64\n",
       "dayOfMonth                           int64\n",
       "day_x_hour                           int64\n",
       "lagged_revenue_D_1                 float64\n",
       "lagged_revenue_H_1                 float64\n",
       "holiday_mean_encoded               float64\n",
       "current_weather_component_1        float64\n",
       "current_weather_component_2        float64\n",
       "weather_diff_to_exp_component_1    float64\n",
       "coronaImpact                       float64\n",
       "yhat                               float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_data = pd.read_csv(\"train_data.csv\")\n",
    "# Zeige Dateiformate für jede Spalte an\n",
    "train_data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37982.32887493917\n",
      "72.86686602215696\n",
      "142.6492206408046\n",
      "295.0738320610455\n",
      "28.17776831502573\n"
     ]
    }
   ],
   "source": [
    "# Loss von prediction.csv und groudtrouth von trainings_daten_stuttart_neu.csv berechnen\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "prediction = pd.read_csv(\"prediction.csv\") # yhat\n",
    "groundtruth = pd.read_csv(\"trainings_daten_stuttart_neu.csv\") # revenue\n",
    "\n",
    "# groundtruth an prediction anpassen indem man join / merge über date\n",
    "groundtruth = pd.merge(groundtruth, prediction, on=\"date\")\n",
    "\n",
    "\n",
    "# Berechne Loss\n",
    "loss = mean_squared_error(groundtruth[\"revenue\"], prediction[\"yhat\"])\n",
    "print(loss)\n",
    "\n",
    "# Berechne Loss prozentual\n",
    "loss_percent = loss / np.mean(groundtruth[\"revenue\"])\n",
    "print(loss_percent)\n",
    "\n",
    "# Berechne Loss MAE\n",
    "loss_mae = np.mean(np.abs(groundtruth[\"revenue\"] - prediction[\"yhat\"]))\n",
    "print(loss_mae)\n",
    "\n",
    "# Berechne Loss MAPE\n",
    "# Replace 0 with 1\n",
    "groundtruth[\"revenue\"] = groundtruth[\"revenue\"].replace(0, 1)\n",
    "\n",
    "loss_mape = np.mean(np.abs((groundtruth[\"revenue\"] - prediction[\"yhat\"]) / groundtruth[\"revenue\"])) * 100\n",
    "print(loss_mape)\n",
    "\n",
    "# Berechne Loss MedianAPE  \n",
    "loss_medianape = np.median(np.abs((groundtruth[\"revenue\"] - prediction[\"yhat\"]) / groundtruth[\"revenue\"])) * 100\n",
    "print(loss_medianape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33893.43446773474\n",
      "65.02256237428092\n",
      "137.86403904885677\n",
      "268.93874230412695\n",
      "27.31931467399715\n"
     ]
    }
   ],
   "source": [
    "# Loss von prediction.csv und groudtrouth von trainings_daten_stuttart_neu.csv berechnen\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "prediction = pd.read_csv(\"prediction (1).csv\") # yhat\n",
    "groundtruth = pd.read_csv(\"trainings_daten_stuttart_neu.csv\") # revenue\n",
    "\n",
    "# groundtruth an prediction anpassen indem man join / merge über date\n",
    "groundtruth = pd.merge(groundtruth, prediction, on=\"date\")\n",
    "\n",
    "\n",
    "# Berechne Loss\n",
    "loss = mean_squared_error(groundtruth[\"revenue\"], prediction[\"yhat\"])\n",
    "print(loss)\n",
    "\n",
    "# Berechne Loss prozentual\n",
    "loss_percent = loss / np.mean(groundtruth[\"revenue\"])\n",
    "print(loss_percent)\n",
    "\n",
    "# Berechne Loss MAE\n",
    "loss_mae = np.mean(np.abs(groundtruth[\"revenue\"] - prediction[\"yhat\"]))\n",
    "print(loss_mae)\n",
    "\n",
    "# Berechne Loss MAPE\n",
    "# Replace 0 with 1\n",
    "groundtruth[\"revenue\"] = groundtruth[\"revenue\"].replace(0, 1)\n",
    "\n",
    "loss_mape = np.mean(np.abs((groundtruth[\"revenue\"] - prediction[\"yhat\"]) / groundtruth[\"revenue\"])) * 100\n",
    "print(loss_mape)\n",
    "\n",
    "# Berechne Loss MedianAPE  \n",
    "loss_medianape = np.median(np.abs((groundtruth[\"revenue\"] - prediction[\"yhat\"]) / groundtruth[\"revenue\"])) * 100\n",
    "print(loss_medianape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06490353417216756"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vergleiche die Losses\n",
    "diff = loss - loss2\n",
    "diff / loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['day_x_hour', 'lagged_revenue_D_1', 'lagged_revenue_H_1',\n",
      "       'holiday_mean_encoded', 'current_weather_component_1',\n",
      "       'current_weather_component_2', 'weather_diff_to_exp_component_1',\n",
      "       'revenue', 'hour_sin', 'hour_cos', 'dayOfMonth_sin', 'dayOfMonth_cos'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# GPR \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "train_data = pd.read_csv(\"train_data_till_2023.csv\")\n",
    "# remove columns \"year\", \"week\", \"coronaImapct\", because they are not needed\n",
    "train_data = train_data.drop(columns=[\"year\", \"week\", \"coronaImpact\"])\n",
    "# reduce to the last 2 years\n",
    "last_date = train_data.iloc[train_data.last_valid_index()].date\n",
    "last_date = pd.to_datetime(last_date)\n",
    "last_date = last_date - pd.DateOffset(years=2)\n",
    "train_data = train_data[pd.to_datetime(train_data.date) > last_date]\n",
    "train_data.set_index(\"date\", inplace=True)\n",
    "# train_data.to_csv(\"train_data_till_2023_last_2_years.csv\")\n",
    "\n",
    "# Sinus and Cosinus Transformation for \"hour\" and \"dayOfMonth\"\n",
    "train_data[\"hour_sin\"] = np.sin(2 * np.pi * train_data[\"hour\"] / 24)\n",
    "train_data[\"hour_cos\"] = np.cos(2 * np.pi * train_data[\"hour\"] / 24)\n",
    "train_data[\"dayOfMonth_sin\"] = np.sin(2 * np.pi * train_data[\"dayOfMonth\"] / 31)\n",
    "train_data[\"dayOfMonth_cos\"] = np.cos(2 * np.pi * train_data[\"dayOfMonth\"] / 31)\n",
    "train_data = train_data.drop(columns=[\"hour\", \"dayOfMonth\"])\n",
    "print(train_data.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import ExpSineSquared, Matern, Sum\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Laden der Daten\n",
    "file_path = 'train_data_till_2023_last_year.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "data[\"sin_hour\"] = np.sin(2 * np.pi * data[\"hour\"] / 24)\n",
    "data[\"cos_hour\"] = np.cos(2 * np.pi * data[\"hour\"] / 24)\n",
    "data[\"sin_dayOfMonth\"] = np.sin(2 * np.pi * data[\"dayOfMonth\"] / 31)\n",
    "data[\"cos_dayOfMonth\"] = np.cos(2 * np.pi * data[\"dayOfMonth\"] / 31)\n",
    "data = data.drop(columns=[\"hour\", \"dayOfMonth\"])\n",
    "\n",
    "# Umwandlung des 'date'-Feldes in ein datetime-Objekt\n",
    "data['date'] = pd.to_datetime(data['date'])\n",
    "\n",
    "# Auswählen des Testdatensatzes (letzter Monat)\n",
    "last_month = data['date'].dt.month.max()\n",
    "test_data = data[data['date'].dt.month == last_month]\n",
    "train_data = data[data['date'].dt.month != last_month]\n",
    "\n",
    "# Zielvariable\n",
    "target_col = 'revenue'\n",
    "\n",
    "# Auswahl der Features\n",
    "# features = ['sin_hour', 'cos_hour', 'sin_dayOfMonth', 'cos_dayOfMonth', 'lagged_revenue_D_1', 'lagged_revenue_H_1', 'holiday_mean_encoded', 'current_weather_component_1', 'current_weather_component_2', 'weather_diff_to_exp_component_1']\n",
    "\n",
    "X_train = train_data.drop(columns=[target_col])\n",
    "y_train = train_data[target_col]\n",
    "X_test = test_data.drop(columns=[target_col])\n",
    "y_test = test_data[target_col]\n",
    "\n",
    "# Skalierung der Features\n",
    "# scaler = StandardScaler()\n",
    "# X_train_scaled = scaler.fit_transform(X_train)\n",
    "# X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# # Kernel-Kombination\n",
    "# periodic_kernel = ExpSineSquared(length_scale=1.0, periodicity=24, length_scale_bounds=(0.1, 10.0), periodicity_bounds=(12, 36))\n",
    "# matern_kernel = Matern(length_scale=1.0, length_scale_bounds=(0.1, 10.0), nu=1.5)\n",
    "# kernel = Sum(periodic_kernel, matern_kernel)\n",
    "\n",
    "# # Gaussian Process Regressor\n",
    "# gpr = GaussianProcessRegressor(kernel=kernel, normalize_y=True)\n",
    "\n",
    "# print(\"hier\")\n",
    "# # Modelltraining\n",
    "# gpr.fit(X_train_scaled, y_train)\n",
    "# print(\"hier2\")\n",
    "# # Vorhersagen\n",
    "# y_pred, y_std = gpr.predict(X_test_scaled, return_std=True)\n",
    "\n",
    "# Hier könnten Sie die Vorhersagen (y_pred) und die Standardabweichungen der Vorhersagen (y_std) weiter analysieren oder visualisieren\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['date', 'year', 'week', 'hour', 'dayOfMonth', 'day_x_hour',\n",
      "       'lagged_revenue_D_1', 'lagged_revenue_H_1', 'holiday_mean_encoded',\n",
      "       'current_weather_component_1', 'current_weather_component_2',\n",
      "       'weather_diff_to_exp_component_1', 'coronaImpact', 'revenue'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['date', 'year', 'week', 'hour', 'dayOfMonth', 'day_x_hour',\n",
       "       'lagged_revenue_D_1', 'lagged_revenue_H_1', 'holiday_mean_encoded',\n",
       "       'current_weather_component_1', 'current_weather_component_2',\n",
       "       'weather_diff_to_exp_component_1', 'coronaImpact', 'revenue'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finde die Startzeit des Tages und die Endzeit des Tages in den Trainingsdaten heraus\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "train_data = pd.read_csv(\"train_data_till_2023.csv\")\n",
    "\n",
    "def preprocess_data(data):\n",
    "    # Entferne aus den Trainingsdaten die Zeilen, die um 23 Uhr sind, weil wir nur an Samstag Sonntag bis 23 Uhr offen haben, das aber unsere\n",
    "    # Periodizität kaputt macht\n",
    "    data = data[data[\"hour\"] != 23]\n",
    "\n",
    "    #Entferne die Spalten \"year\", \"week\", \"coronaImpact\", weil diese keinen Impact haben\n",
    "    data = data.drop(columns=[\"year\", \"week\", \"coronaImpact\"])\n",
    "\n",
    "    # Sinus and Cosinus Transformation for \"hour\" and \"dayOfMonth\"\n",
    "    data[\"hour_sin\"] = np.sin(2 * np.pi * data[\"hour\"] / 24)\n",
    "    data[\"hour_cos\"] = np.cos(2 * np.pi * data[\"hour\"] / 24)\n",
    "    data[\"dayOfMonth_sin\"] = np.sin(2 * np.pi * data[\"dayOfMonth\"] / 31)\n",
    "    data[\"dayOfMonth_cos\"] = np.cos(2 * np.pi * data[\"dayOfMonth\"] / 31)\n",
    "    data = data.drop(columns=[\"hour\", \"dayOfMonth\"])\n",
    "\n",
    "    return data\n",
    "\n",
    "def split_train_test_data(data, target_col=\"revenue\"):\n",
    "    # Auswählen des Testdatensatzes (letzter Monat)\n",
    "    last_month = data['date'].dt.month.max()\n",
    "    test_data = data[data['date'].dt.month == last_month]\n",
    "    train_data = data[data['date'].dt.month != last_month]\n",
    "\n",
    "    # Reduziere die Trainingsdaten auf die letzten 2 Jahre\n",
    "    last_date = train_data.iloc[train_data.last_valid_index()].date\n",
    "    last_date = pd.to_datetime(last_date)\n",
    "    last_date = last_date - pd.DateOffset(years=2)\n",
    "    train_data = train_data[pd.to_datetime(train_data.date) > last_date]\n",
    "\n",
    "    # x, y trennen\n",
    "    X_train = train_data.drop(columns=[target_col])\n",
    "    y_train = train_data[target_col]\n",
    "    X_test = test_data.drop(columns=[target_col])\n",
    "    y_test = test_data[target_col]\n",
    "\n",
    "    return X_train, y_train, X_test, y_test\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>year</th>\n",
       "      <th>week</th>\n",
       "      <th>day_x_hour</th>\n",
       "      <th>lagged_revenue_D_1</th>\n",
       "      <th>lagged_revenue_H_1</th>\n",
       "      <th>holiday_mean_encoded</th>\n",
       "      <th>current_weather_component_1</th>\n",
       "      <th>current_weather_component_2</th>\n",
       "      <th>weather_diff_to_exp_component_1</th>\n",
       "      <th>coronaImpact</th>\n",
       "      <th>sin_hour</th>\n",
       "      <th>cos_hour</th>\n",
       "      <th>sin_dayOfMonth</th>\n",
       "      <th>cos_dayOfMonth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-08-31 12:00:00</td>\n",
       "      <td>2022</td>\n",
       "      <td>35</td>\n",
       "      <td>312</td>\n",
       "      <td>5724.04</td>\n",
       "      <td>206.86</td>\n",
       "      <td>203.929657</td>\n",
       "      <td>0.218699</td>\n",
       "      <td>0.010977</td>\n",
       "      <td>-0.048941</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.224647e-16</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>-2.449294e-16</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-08-31 13:00:00</td>\n",
       "      <td>2022</td>\n",
       "      <td>35</td>\n",
       "      <td>313</td>\n",
       "      <td>5724.04</td>\n",
       "      <td>342.23</td>\n",
       "      <td>319.399739</td>\n",
       "      <td>0.238869</td>\n",
       "      <td>0.018858</td>\n",
       "      <td>-0.029861</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-2.588190e-01</td>\n",
       "      <td>-9.659258e-01</td>\n",
       "      <td>-2.449294e-16</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-08-31 14:00:00</td>\n",
       "      <td>2022</td>\n",
       "      <td>35</td>\n",
       "      <td>314</td>\n",
       "      <td>5724.04</td>\n",
       "      <td>159.64</td>\n",
       "      <td>213.286592</td>\n",
       "      <td>0.252323</td>\n",
       "      <td>0.036408</td>\n",
       "      <td>-0.013234</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-5.000000e-01</td>\n",
       "      <td>-8.660254e-01</td>\n",
       "      <td>-2.449294e-16</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-08-31 15:00:00</td>\n",
       "      <td>2022</td>\n",
       "      <td>35</td>\n",
       "      <td>315</td>\n",
       "      <td>5724.04</td>\n",
       "      <td>421.20</td>\n",
       "      <td>276.163487</td>\n",
       "      <td>0.272492</td>\n",
       "      <td>0.044289</td>\n",
       "      <td>0.005485</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-7.071068e-01</td>\n",
       "      <td>-7.071068e-01</td>\n",
       "      <td>-2.449294e-16</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-08-31 16:00:00</td>\n",
       "      <td>2022</td>\n",
       "      <td>35</td>\n",
       "      <td>316</td>\n",
       "      <td>5724.04</td>\n",
       "      <td>261.70</td>\n",
       "      <td>228.186135</td>\n",
       "      <td>0.357466</td>\n",
       "      <td>0.026523</td>\n",
       "      <td>0.069102</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-8.660254e-01</td>\n",
       "      <td>-5.000000e-01</td>\n",
       "      <td>-2.449294e-16</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4091</th>\n",
       "      <td>2023-08-30 18:00:00</td>\n",
       "      <td>2023</td>\n",
       "      <td>35</td>\n",
       "      <td>318</td>\n",
       "      <td>7343.24</td>\n",
       "      <td>1121.17</td>\n",
       "      <td>772.340691</td>\n",
       "      <td>-0.227331</td>\n",
       "      <td>0.194195</td>\n",
       "      <td>-0.298434</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>-1.836970e-16</td>\n",
       "      <td>-2.012985e-01</td>\n",
       "      <td>0.97953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4092</th>\n",
       "      <td>2023-08-30 19:00:00</td>\n",
       "      <td>2023</td>\n",
       "      <td>35</td>\n",
       "      <td>319</td>\n",
       "      <td>7343.24</td>\n",
       "      <td>1583.67</td>\n",
       "      <td>1016.308439</td>\n",
       "      <td>-0.049350</td>\n",
       "      <td>0.193159</td>\n",
       "      <td>-0.145240</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-9.659258e-01</td>\n",
       "      <td>2.588190e-01</td>\n",
       "      <td>-2.012985e-01</td>\n",
       "      <td>0.97953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4093</th>\n",
       "      <td>2023-08-30 20:00:00</td>\n",
       "      <td>2023</td>\n",
       "      <td>35</td>\n",
       "      <td>320</td>\n",
       "      <td>7343.24</td>\n",
       "      <td>569.16</td>\n",
       "      <td>779.150115</td>\n",
       "      <td>-0.074029</td>\n",
       "      <td>0.235094</td>\n",
       "      <td>-0.154490</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-8.660254e-01</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>-2.012985e-01</td>\n",
       "      <td>0.97953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4094</th>\n",
       "      <td>2023-08-30 21:00:00</td>\n",
       "      <td>2023</td>\n",
       "      <td>35</td>\n",
       "      <td>321</td>\n",
       "      <td>7343.24</td>\n",
       "      <td>388.23</td>\n",
       "      <td>475.956513</td>\n",
       "      <td>-0.127888</td>\n",
       "      <td>0.238170</td>\n",
       "      <td>-0.188675</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-7.071068e-01</td>\n",
       "      <td>7.071068e-01</td>\n",
       "      <td>-2.012985e-01</td>\n",
       "      <td>0.97953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4095</th>\n",
       "      <td>2023-08-30 22:00:00</td>\n",
       "      <td>2023</td>\n",
       "      <td>35</td>\n",
       "      <td>322</td>\n",
       "      <td>7343.24</td>\n",
       "      <td>122.02</td>\n",
       "      <td>125.677691</td>\n",
       "      <td>-0.337956</td>\n",
       "      <td>0.165969</td>\n",
       "      <td>-0.332112</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-5.000000e-01</td>\n",
       "      <td>8.660254e-01</td>\n",
       "      <td>-2.012985e-01</td>\n",
       "      <td>0.97953</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3745 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    date  year  week  day_x_hour  lagged_revenue_D_1  \\\n",
       "0    2022-08-31 12:00:00  2022    35         312             5724.04   \n",
       "1    2022-08-31 13:00:00  2022    35         313             5724.04   \n",
       "2    2022-08-31 14:00:00  2022    35         314             5724.04   \n",
       "3    2022-08-31 15:00:00  2022    35         315             5724.04   \n",
       "4    2022-08-31 16:00:00  2022    35         316             5724.04   \n",
       "...                  ...   ...   ...         ...                 ...   \n",
       "4091 2023-08-30 18:00:00  2023    35         318             7343.24   \n",
       "4092 2023-08-30 19:00:00  2023    35         319             7343.24   \n",
       "4093 2023-08-30 20:00:00  2023    35         320             7343.24   \n",
       "4094 2023-08-30 21:00:00  2023    35         321             7343.24   \n",
       "4095 2023-08-30 22:00:00  2023    35         322             7343.24   \n",
       "\n",
       "      lagged_revenue_H_1  holiday_mean_encoded  current_weather_component_1  \\\n",
       "0                 206.86            203.929657                     0.218699   \n",
       "1                 342.23            319.399739                     0.238869   \n",
       "2                 159.64            213.286592                     0.252323   \n",
       "3                 421.20            276.163487                     0.272492   \n",
       "4                 261.70            228.186135                     0.357466   \n",
       "...                  ...                   ...                          ...   \n",
       "4091             1121.17            772.340691                    -0.227331   \n",
       "4092             1583.67           1016.308439                    -0.049350   \n",
       "4093              569.16            779.150115                    -0.074029   \n",
       "4094              388.23            475.956513                    -0.127888   \n",
       "4095              122.02            125.677691                    -0.337956   \n",
       "\n",
       "      current_weather_component_2  weather_diff_to_exp_component_1  \\\n",
       "0                        0.010977                        -0.048941   \n",
       "1                        0.018858                        -0.029861   \n",
       "2                        0.036408                        -0.013234   \n",
       "3                        0.044289                         0.005485   \n",
       "4                        0.026523                         0.069102   \n",
       "...                           ...                              ...   \n",
       "4091                     0.194195                        -0.298434   \n",
       "4092                     0.193159                        -0.145240   \n",
       "4093                     0.235094                        -0.154490   \n",
       "4094                     0.238170                        -0.188675   \n",
       "4095                     0.165969                        -0.332112   \n",
       "\n",
       "      coronaImpact      sin_hour      cos_hour  sin_dayOfMonth  cos_dayOfMonth  \n",
       "0              1.0  1.224647e-16 -1.000000e+00   -2.449294e-16         1.00000  \n",
       "1              1.0 -2.588190e-01 -9.659258e-01   -2.449294e-16         1.00000  \n",
       "2              1.0 -5.000000e-01 -8.660254e-01   -2.449294e-16         1.00000  \n",
       "3              1.0 -7.071068e-01 -7.071068e-01   -2.449294e-16         1.00000  \n",
       "4              1.0 -8.660254e-01 -5.000000e-01   -2.449294e-16         1.00000  \n",
       "...            ...           ...           ...             ...             ...  \n",
       "4091           1.0 -1.000000e+00 -1.836970e-16   -2.012985e-01         0.97953  \n",
       "4092           1.0 -9.659258e-01  2.588190e-01   -2.012985e-01         0.97953  \n",
       "4093           1.0 -8.660254e-01  5.000000e-01   -2.012985e-01         0.97953  \n",
       "4094           1.0 -7.071068e-01  7.071068e-01   -2.012985e-01         0.97953  \n",
       "4095           1.0 -5.000000e-01  8.660254e-01   -2.012985e-01         0.97953  \n",
       "\n",
       "[3745 rows x 15 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF, WhiteKernel\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import scipy\n",
    "\n",
    "# Definiere den Suchraum für die Hyperparameter\n",
    "param_distributions = {'kernel__k1__length_scale': scipy.stats.uniform(0.1, 10),\n",
    "                       'kernel__k2__noise_level': scipy.stats.uniform(1e-5, 1e-1),\n",
    "                       'alpha': scipy.stats.uniform(1e-10, 1e-5)}\n",
    "\n",
    "# Erstelle den Kernel (Kombination aus RBF und WhiteKernel)\n",
    "kernel = RBF() + WhiteKernel()\n",
    "\n",
    "# Initialisiere das GPR-Modell\n",
    "gpr = GaussianProcessRegressor(kernel=kernel, random_state=42)\n",
    "\n",
    "# Führe die zufällige Hyperparameter-Suche durch\n",
    "random_search = RandomizedSearchCV(gpr, param_distributions=param_distributions,\n",
    "                                   n_iter=100, cv=5, scoring='neg_mean_squared_error',\n",
    "                                   random_state=42, n_jobs=-1, verbose=1)\n",
    "\n",
    "# Trainiere das Modell mit den optimierten Hyperparametern\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Nutze das beste Modell für Vorhersagen\n",
    "y_pred = random_search.best_estimator_.predict(X_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
