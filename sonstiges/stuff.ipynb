{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "x = pd.read_csv('x_trainings_daten_stuttart_neu.csv')\n",
    "y = pd.read_csv('y_trainings_daten_stuttart_neu.csv')\n",
    "\n",
    "# merge on date\n",
    "df = pd.merge(x, y, on='date')\n",
    "df.to_csv('trainings_daten_stuttart_neu.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>year</th>\n",
       "      <th>week</th>\n",
       "      <th>hour</th>\n",
       "      <th>dayOfMonth</th>\n",
       "      <th>day_x_hour</th>\n",
       "      <th>lagged_revenue_D_1</th>\n",
       "      <th>lagged_revenue_H_1</th>\n",
       "      <th>holiday_mean_encoded</th>\n",
       "      <th>current_weather_component_1</th>\n",
       "      <th>current_weather_component_2</th>\n",
       "      <th>weather_diff_to_exp_component_1</th>\n",
       "      <th>coronaImpact</th>\n",
       "      <th>revenue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-01-01 14:00:00</td>\n",
       "      <td>2016</td>\n",
       "      <td>52</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>714</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.528081</td>\n",
       "      <td>-0.191760</td>\n",
       "      <td>0.443502</td>\n",
       "      <td>1.0</td>\n",
       "      <td>58.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-01-01 15:00:00</td>\n",
       "      <td>2016</td>\n",
       "      <td>52</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>715</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.502798</td>\n",
       "      <td>-0.184728</td>\n",
       "      <td>0.428460</td>\n",
       "      <td>1.0</td>\n",
       "      <td>413.580000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-01-01 16:00:00</td>\n",
       "      <td>2016</td>\n",
       "      <td>52</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>716</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.217124</td>\n",
       "      <td>-0.219914</td>\n",
       "      <td>0.227167</td>\n",
       "      <td>1.0</td>\n",
       "      <td>432.590000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-01-01 17:00:00</td>\n",
       "      <td>2016</td>\n",
       "      <td>52</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>717</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.064720</td>\n",
       "      <td>-0.256727</td>\n",
       "      <td>0.029202</td>\n",
       "      <td>1.0</td>\n",
       "      <td>643.620000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-01-01 18:00:00</td>\n",
       "      <td>2016</td>\n",
       "      <td>52</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>718</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.350093</td>\n",
       "      <td>-0.285155</td>\n",
       "      <td>-0.172097</td>\n",
       "      <td>1.0</td>\n",
       "      <td>636.320000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27705</th>\n",
       "      <td>2023-09-30 19:00:00</td>\n",
       "      <td>2023</td>\n",
       "      <td>39</td>\n",
       "      <td>19</td>\n",
       "      <td>30</td>\n",
       "      <td>619</td>\n",
       "      <td>6796.204746</td>\n",
       "      <td>1418.415938</td>\n",
       "      <td>1006.216532</td>\n",
       "      <td>0.286742</td>\n",
       "      <td>0.259476</td>\n",
       "      <td>0.225284</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1503.232958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27706</th>\n",
       "      <td>2023-09-30 20:00:00</td>\n",
       "      <td>2023</td>\n",
       "      <td>39</td>\n",
       "      <td>20</td>\n",
       "      <td>30</td>\n",
       "      <td>620</td>\n",
       "      <td>6796.204746</td>\n",
       "      <td>888.685398</td>\n",
       "      <td>943.098579</td>\n",
       "      <td>0.370658</td>\n",
       "      <td>0.169524</td>\n",
       "      <td>0.267972</td>\n",
       "      <td>1.0</td>\n",
       "      <td>859.612593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27707</th>\n",
       "      <td>2023-09-30 21:00:00</td>\n",
       "      <td>2023</td>\n",
       "      <td>39</td>\n",
       "      <td>21</td>\n",
       "      <td>30</td>\n",
       "      <td>621</td>\n",
       "      <td>6796.204746</td>\n",
       "      <td>401.546930</td>\n",
       "      <td>757.453552</td>\n",
       "      <td>0.424010</td>\n",
       "      <td>0.079618</td>\n",
       "      <td>0.296878</td>\n",
       "      <td>1.0</td>\n",
       "      <td>367.365510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27708</th>\n",
       "      <td>2023-09-30 22:00:00</td>\n",
       "      <td>2023</td>\n",
       "      <td>39</td>\n",
       "      <td>22</td>\n",
       "      <td>30</td>\n",
       "      <td>622</td>\n",
       "      <td>6796.204746</td>\n",
       "      <td>167.692219</td>\n",
       "      <td>427.740709</td>\n",
       "      <td>0.455768</td>\n",
       "      <td>0.053625</td>\n",
       "      <td>0.331928</td>\n",
       "      <td>1.0</td>\n",
       "      <td>166.480406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27709</th>\n",
       "      <td>2023-09-30 23:00:00</td>\n",
       "      <td>2023</td>\n",
       "      <td>39</td>\n",
       "      <td>23</td>\n",
       "      <td>30</td>\n",
       "      <td>623</td>\n",
       "      <td>6796.204746</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>136.389807</td>\n",
       "      <td>0.401862</td>\n",
       "      <td>0.035235</td>\n",
       "      <td>0.306485</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27710 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      date  year  week  hour  dayOfMonth  day_x_hour  \\\n",
       "0      2017-01-01 14:00:00  2016    52    14           1         714   \n",
       "1      2017-01-01 15:00:00  2016    52    15           1         715   \n",
       "2      2017-01-01 16:00:00  2016    52    16           1         716   \n",
       "3      2017-01-01 17:00:00  2016    52    17           1         717   \n",
       "4      2017-01-01 18:00:00  2016    52    18           1         718   \n",
       "...                    ...   ...   ...   ...         ...         ...   \n",
       "27705  2023-09-30 19:00:00  2023    39    19          30         619   \n",
       "27706  2023-09-30 20:00:00  2023    39    20          30         620   \n",
       "27707  2023-09-30 21:00:00  2023    39    21          30         621   \n",
       "27708  2023-09-30 22:00:00  2023    39    22          30         622   \n",
       "27709  2023-09-30 23:00:00  2023    39    23          30         623   \n",
       "\n",
       "       lagged_revenue_D_1  lagged_revenue_H_1  holiday_mean_encoded  \\\n",
       "0                     NaN                 NaN                   NaN   \n",
       "1                     NaN                 NaN                   NaN   \n",
       "2                     NaN                 NaN                   NaN   \n",
       "3                     NaN                 NaN                   NaN   \n",
       "4                     NaN                 NaN                   NaN   \n",
       "...                   ...                 ...                   ...   \n",
       "27705         6796.204746         1418.415938           1006.216532   \n",
       "27706         6796.204746          888.685398            943.098579   \n",
       "27707         6796.204746          401.546930            757.453552   \n",
       "27708         6796.204746          167.692219            427.740709   \n",
       "27709         6796.204746            0.000000            136.389807   \n",
       "\n",
       "       current_weather_component_1  current_weather_component_2  \\\n",
       "0                         0.528081                    -0.191760   \n",
       "1                         0.502798                    -0.184728   \n",
       "2                         0.217124                    -0.219914   \n",
       "3                        -0.064720                    -0.256727   \n",
       "4                        -0.350093                    -0.285155   \n",
       "...                            ...                          ...   \n",
       "27705                     0.286742                     0.259476   \n",
       "27706                     0.370658                     0.169524   \n",
       "27707                     0.424010                     0.079618   \n",
       "27708                     0.455768                     0.053625   \n",
       "27709                     0.401862                     0.035235   \n",
       "\n",
       "       weather_diff_to_exp_component_1  coronaImpact      revenue  \n",
       "0                             0.443502           1.0    58.800000  \n",
       "1                             0.428460           1.0   413.580000  \n",
       "2                             0.227167           1.0   432.590000  \n",
       "3                             0.029202           1.0   643.620000  \n",
       "4                            -0.172097           1.0   636.320000  \n",
       "...                                ...           ...          ...  \n",
       "27705                         0.225284           1.0  1503.232958  \n",
       "27706                         0.267972           1.0   859.612593  \n",
       "27707                         0.296878           1.0   367.365510  \n",
       "27708                         0.331928           1.0   166.480406  \n",
       "27709                         0.306485           1.0     0.000000  \n",
       "\n",
       "[27710 rows x 14 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('trainings_daten_stuttart_neu.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_data = pd.read_csv(\"trainings_daten_stuttart_neu.csv\")\n",
    "\n",
    "last_date = train_data.iloc[train_data.last_valid_index()].date\n",
    "last_date = pd.to_datetime(last_date)\n",
    "last_date = last_date - pd.DateOffset(months=1)\n",
    "test_data = train_data[pd.to_datetime(train_data.date) > last_date]\n",
    "test_data = test_data.drop(columns=[\"revenue\"])\n",
    "train_data = train_data[pd.to_datetime(train_data.date) <= last_date]\n",
    "train_data = train_data.dropna()\n",
    "\n",
    "test_data.set_index(\"date\", inplace=True)\n",
    "train_data.set_index(\"date\", inplace=True)\n",
    "test_data.to_csv(\"test_data_till_2023.csv\")\n",
    "train_data.to_csv(\"train_data_till_2023.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_20029/3773211973.py:2: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "# lade train_data_till_2023.csv und schränke das auf das letzte Jahr ein (so dass das neue df noch ein jahr an daten hat) und speichere das als train_data_till_2023_last_year.csv\n",
    "import pandas as pd\n",
    "\n",
    "train_data = pd.read_csv(\"train_data_till_2023.csv\")\n",
    "last_date = train_data.iloc[train_data.last_valid_index()].date\n",
    "last_date = pd.to_datetime(last_date)\n",
    "last_date = last_date - pd.DateOffset(years=1)\n",
    "train_data = train_data[pd.to_datetime(train_data.date) > last_date]\n",
    "train_data.set_index(\"date\", inplace=True)\n",
    "train_data.to_csv(\"train_data_till_2023_last_year.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date                                object\n",
       "year                                 int64\n",
       "week                                 int64\n",
       "hour                                 int64\n",
       "dayOfMonth                           int64\n",
       "day_x_hour                           int64\n",
       "lagged_revenue_D_1                 float64\n",
       "lagged_revenue_H_1                 float64\n",
       "holiday_mean_encoded               float64\n",
       "current_weather_component_1        float64\n",
       "current_weather_component_2        float64\n",
       "weather_diff_to_exp_component_1    float64\n",
       "coronaImpact                       float64\n",
       "yhat                               float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_data = pd.read_csv(\"train_data.csv\")\n",
    "# Zeige Dateiformate für jede Spalte an\n",
    "train_data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37982.32887493917\n",
      "72.86686602215696\n",
      "142.6492206408046\n",
      "295.0738320610455\n",
      "28.17776831502573\n"
     ]
    }
   ],
   "source": [
    "# Loss von prediction.csv und groudtrouth von trainings_daten_stuttart_neu.csv berechnen\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "prediction = pd.read_csv(\"prediction.csv\") # yhat\n",
    "groundtruth = pd.read_csv(\"trainings_daten_stuttart_neu.csv\") # revenue\n",
    "\n",
    "# groundtruth an prediction anpassen indem man join / merge über date\n",
    "groundtruth = pd.merge(groundtruth, prediction, on=\"date\")\n",
    "\n",
    "\n",
    "# Berechne Loss\n",
    "loss = mean_squared_error(groundtruth[\"revenue\"], prediction[\"yhat\"])\n",
    "print(loss)\n",
    "\n",
    "# Berechne Loss prozentual\n",
    "loss_percent = loss / np.mean(groundtruth[\"revenue\"])\n",
    "print(loss_percent)\n",
    "\n",
    "# Berechne Loss MAE\n",
    "loss_mae = np.mean(np.abs(groundtruth[\"revenue\"] - prediction[\"yhat\"]))\n",
    "print(loss_mae)\n",
    "\n",
    "# Berechne Loss MAPE\n",
    "# Replace 0 with 1\n",
    "groundtruth[\"revenue\"] = groundtruth[\"revenue\"].replace(0, 1)\n",
    "\n",
    "loss_mape = np.mean(np.abs((groundtruth[\"revenue\"] - prediction[\"yhat\"]) / groundtruth[\"revenue\"])) * 100\n",
    "print(loss_mape)\n",
    "\n",
    "# Berechne Loss MedianAPE  \n",
    "loss_medianape = np.median(np.abs((groundtruth[\"revenue\"] - prediction[\"yhat\"]) / groundtruth[\"revenue\"])) * 100\n",
    "print(loss_medianape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33893.43446773474\n",
      "65.02256237428092\n",
      "137.86403904885677\n",
      "268.93874230412695\n",
      "27.31931467399715\n"
     ]
    }
   ],
   "source": [
    "# Loss von prediction.csv und groudtrouth von trainings_daten_stuttart_neu.csv berechnen\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "prediction = pd.read_csv(\"prediction (1).csv\") # yhat\n",
    "groundtruth = pd.read_csv(\"trainings_daten_stuttart_neu.csv\") # revenue\n",
    "\n",
    "# groundtruth an prediction anpassen indem man join / merge über date\n",
    "groundtruth = pd.merge(groundtruth, prediction, on=\"date\")\n",
    "\n",
    "\n",
    "# Berechne Loss\n",
    "loss = mean_squared_error(groundtruth[\"revenue\"], prediction[\"yhat\"])\n",
    "print(loss)\n",
    "\n",
    "# Berechne Loss prozentual\n",
    "loss_percent = loss / np.mean(groundtruth[\"revenue\"])\n",
    "print(loss_percent)\n",
    "\n",
    "# Berechne Loss MAE\n",
    "loss_mae = np.mean(np.abs(groundtruth[\"revenue\"] - prediction[\"yhat\"]))\n",
    "print(loss_mae)\n",
    "\n",
    "# Berechne Loss MAPE\n",
    "# Replace 0 with 1\n",
    "groundtruth[\"revenue\"] = groundtruth[\"revenue\"].replace(0, 1)\n",
    "\n",
    "loss_mape = np.mean(np.abs((groundtruth[\"revenue\"] - prediction[\"yhat\"]) / groundtruth[\"revenue\"])) * 100\n",
    "print(loss_mape)\n",
    "\n",
    "# Berechne Loss MedianAPE  \n",
    "loss_medianape = np.median(np.abs((groundtruth[\"revenue\"] - prediction[\"yhat\"]) / groundtruth[\"revenue\"])) * 100\n",
    "print(loss_medianape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06490353417216756"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vergleiche die Losses\n",
    "diff = loss - loss2\n",
    "diff / loss "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
